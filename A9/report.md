---
title: "演講報告 - Security and Privacy of Deep Language Models"
author: "313832008 簡蔚驊"
CJKmainfont: "Noto Sans CJK TC"
fontsize: 12pt
geometry: "a4paper, top=2.54cm, bottom=2.54cm, left=2.54cm, right=2.54cm"
---

今天參加了「Security and Privacy of Deep Language Models」的演講，對於 LLM 的基礎原理和安全性議題有了更全面的認識，也引發了我對於這些技術背後潛在風險和解決方案的深思。

### LLM 架構的重新認識

演講的前半段講者講解了 LLM 的基礎架構，包括 Transformer 的編碼器（Encoder）、解碼器（Decoder）以及核心的自注意力機制（Self-Attention）。講者特別強調位置編碼（Positional Encoding）對序列資訊的保留，這讓我重新意識到 Transformer 的設計不只是靈活，更是對序列結構的充分尊重與運用。這一部分的複習對我來說非常有價值，不僅讓我更清楚模型如何處理語言資訊，也讓我重新認識到這些技術的核心設計理念。

### 安全與隱私議題的深度探討

後半段演講中，講者深入探討了 LLM 面臨的各種安全性與隱私挑戰。講解 Jailbreak 攻擊，像 DAN 和 AutoDAN，展示了如何透過設計巧妙的提示（Prompt）繞過模型的內建限制，從而獲取原本不應該生成的敏感資訊。這不僅我讓驚訝於攻擊手段的創意與巧妙，也讓我意識到模型防禦機制的重要性。

講者提到的 SmoothLLM 方法，透過多次隨機擾動輸入並聚合結果，有效抵禦了提示工程攻擊，讓我看到即便在現有模型上，仍然可以透過創新策略提升安全性。此外，差分隱私（Differential Privacy, DP）的應用也是關注的重點。演講中詳細解釋了 DP 在梯度裁剪與噪聲注入中的應用，並探討了 DP 微調（Finetuning）與從頭訓練（Training from Scratch）在保護模型隱私時的優劣勢。在實際應用中如何平衡隱私強度與模型效能，是一個需要持續探索的課題。

### 實務應用與反思

講者指出 LLM 在預訓練階段就有可能吸收帶有隱私或版權的數據，而這些數據一旦被惡意使用者透過提取技術鎖定，可能引發嚴重的隱私洩漏問題。模型的安全性不僅僅是後端防禦策略的問題，更需要從數據收集、過濾到訓練全流程中進行規劃與管理。例如，利用 DP 技術降低單一數據樣本對模型的影響，或是通過更加嚴格的數據去識別化（De-identification）流程來減少風險。

在講者探討 Finetuning 與 Training from Scratch，題到當資源有限時，是否應該在隱私強度上妥協以保證模型性能？還是說，可以通過引入高質量數據或使用分布式計算等技術，來同時兼顧隱私與效能？這些問題都讓我對 LLM 的應用和開發有了更深的思考。

### 總結

整場演講讓我重新認識了 LLM 的技術基礎，也開拓了我對安全與隱私議題的視野。從 Transformer 的細節設計到模型在實際應用中的風險，這次演講強調的不僅是技術層面的提升，還有對應的倫理責任與法規遵循的重要性。